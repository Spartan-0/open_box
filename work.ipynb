{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0621821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alaska-airlines-and-horizon-air-sms-manual-index\n"
     ]
    }
   ],
   "source": [
    "pdf_file_name = \"Alaska Airlines and Horizon Air SMS Manual.pdf\"\n",
    "#print(pdf_file_name.split(\".\")[0].replace(\" \",\"_\"))\n",
    "index_name = str(pdf_file_name.split(\".\")[0].lower().replace(\" \",\"-\") + \"-index\")\n",
    "print(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "105cffcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install azure-search-documents==11.4.0b8\n",
    "#!pip install azure-identity\n",
    "#!pip install openai\n",
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9440cf4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560b8dea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9798c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
    "#from dotenv import load_dotenv\n",
    "\n",
    "from langchain.vectorstores.azuresearch import AzureSearch\n",
    "from langchain.document_loaders import AzureBlobStorageContainerLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "#from dotenv import dotenv_values\n",
    "import openai\n",
    "import os\n",
    "#from azure.search.documents.indexes import *\n",
    "\n",
    "openai.api_key = \"ea0464cc-8e3d-4eda-a0d4-9be234678a2f\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e74ae3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_TYPE\"] = \"azure\"\n",
    "os.environ[\"OPENAI_API_BASE\"] = \"https://testingchat.openai.azure.com/\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"e8143eabb02541259054426630db12a7\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2023-05-15\"\n",
    "model: str = \"text-embedding-ada-002\"\n",
    "pdf_file_name = \"Alaska Airlines and Horizon Air SMS Manual.pdf\"   \n",
    "#e8143eabb02541259054426630db12a7    \n",
    "\n",
    "#vector_store_address: str = \"https://genaisafety.search.windows.net\"\n",
    "#vector_store_password: str = \"iDXpfwNsnwyN88dYUlj3c0TaXP76z1DlWlSxZ9QmPxAzSeAu7ppU\"\n",
    "\n",
    "AZURE_SEARCH_SERVICE_ENDPOINT = \"https://genaisafety.search.windows.net\"\n",
    "AZURE_SEARCH_ADMIN_KEY = \"jA50VnyT0OAeuHpY0RxJGz7z9kfrmdj7YF5PHYiPXjAzSeBS6hJg\"\n",
    "\n",
    "#Creating Serach index\n",
    "\n",
    "AZURE_SEARCH_INDEX_NAME = str(pdf_file_name.split(\".\")[0].lower().replace(\" \",\"-\") + \"-index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d32d10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade azure-search-documents\n",
    "embeddings = OpenAIEmbeddings(deployment = model,chunk_size=1) \n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=AZURE_SEARCH_SERVICE_ENDPOINT,\n",
    "    azure_search_key=AZURE_SEARCH_ADMIN_KEY,\n",
    "    index_name = AZURE_SEARCH_INDEX_NAME,\n",
    "    embedding_function=embeddings.embed_query,\n",
    ")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7929c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install azure-search-documents --pre\n",
    "#%pip show azure-search-documents\n",
    "\n",
    "import os\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents.indexes import SearchIndexClient \n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    ComplexField,\n",
    "    VectorSearch,\n",
    "    HnswVectorSearchAlgorithmConfiguration,\n",
    "    SearchField,\n",
    "    CorsOptions,\n",
    "    SearchIndex,\n",
    "    ScoringProfile,\n",
    "    SearchFieldDataType,\n",
    "    SimpleField,\n",
    "    SearchableField,\n",
    ")\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "#pdf_file_name = \"Alaska Airlines and Horizon Air SMS Manual.pdf\"\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.search.documents import IndexDocumentsBatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6b9e205b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_text_extraction(pdf_file_path):\n",
    "    if pdf_file_path is not None:\n",
    "        # Open the PDF file and read its contents\n",
    "        with open(pdf_file_path, 'rb') as pdf_file:\n",
    "            # Create a temporary file to write the PDF contents\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "                tmp_file.write(pdf_file.read())\n",
    "                pdf_path = tmp_file.name\n",
    "\n",
    "        # Now you can use the PyPDFLoader on the temporary PDF file\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages_split = loader.load_and_split()\n",
    "    return pages_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d4bb2e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manuals/AAG_Safety_Manual.pdf\n",
      "AAG_Safety_Manual.pdf\n",
      "PDF file downloaded successfully.\n",
      "splitted into 125 documents\n",
      "aag-safety-manual-index\n",
      "splitted into 125 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(InvalidRequestParameter) The request is invalid. Details: definition : The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined.\nCode: InvalidRequestParameter\nMessage: The request is invalid. Details: definition : The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined.\nException Details:\t(UnknownVectorAlgorithmConfiguration) The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined. Parameters: definition\n\tCode: UnknownVectorAlgorithmConfiguration\n\tMessage: The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined. Parameters: definition",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 105\u001b[0m\n\u001b[1;32m    102\u001b[0m index \u001b[38;5;241m=\u001b[39m SearchIndex(name\u001b[38;5;241m=\u001b[39mAZURE_SEARCH_INDEX_NAME, fields \u001b[38;5;241m=\u001b[39m fields,)\n\u001b[1;32m    104\u001b[0m \u001b[38;5;66;03m# Create the new index\u001b[39;00m\n\u001b[0;32m--> 105\u001b[0m search_client\u001b[38;5;241m.\u001b[39mcreate_or_update_index(index)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m#print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' created successfully.\")\u001b[39;00m\n\u001b[1;32m    107\u001b[0m result \u001b[38;5;241m=\u001b[39m search_client_v2\u001b[38;5;241m.\u001b[39mupload_documents(documents\u001b[38;5;241m=\u001b[39mdict_data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/azure/search/documents/indexes/_search_index_client.py:256\u001b[0m, in \u001b[0;36mSearchIndexClient.create_or_update_index\u001b[0;34m(self, index, allow_index_downtime, match_condition, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m kwargs\u001b[38;5;241m.\u001b[39mupdate(access_condition)\n\u001b[1;32m    255\u001b[0m patched_index \u001b[38;5;241m=\u001b[39m index\u001b[38;5;241m.\u001b[39m_to_generated()  \u001b[38;5;66;03m# pylint:disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 256\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mindexes\u001b[38;5;241m.\u001b[39mcreate_or_update(\n\u001b[1;32m    257\u001b[0m     index_name\u001b[38;5;241m=\u001b[39mindex\u001b[38;5;241m.\u001b[39mname,\n\u001b[1;32m    258\u001b[0m     index\u001b[38;5;241m=\u001b[39mpatched_index,\n\u001b[1;32m    259\u001b[0m     allow_index_downtime\u001b[38;5;241m=\u001b[39mallow_index_downtime,\n\u001b[1;32m    260\u001b[0m     prefer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn=representation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    261\u001b[0m     error_map\u001b[38;5;241m=\u001b[39merror_map,\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    263\u001b[0m )\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m SearchIndex\u001b[38;5;241m.\u001b[39m_from_generated(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/azure/core/tracing/decorator.py:78\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m span_impl_type \u001b[38;5;241m=\u001b[39m settings\u001b[38;5;241m.\u001b[39mtracing_implementation()\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m span_impl_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/azure/search/documents/indexes/_generated/operations/_indexes_operations.py:722\u001b[0m, in \u001b[0;36mIndexesOperations.create_or_update\u001b[0;34m(self, index_name, prefer, index, allow_index_downtime, if_match, if_none_match, request_options, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[1;32m    721\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize\u001b[38;5;241m.\u001b[39mfailsafe_deserialize(_models\u001b[38;5;241m.\u001b[39mSearchError, pipeline_response)\n\u001b[0;32m--> 722\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse, model\u001b[38;5;241m=\u001b[39merror)\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m    725\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deserialize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearchIndex\u001b[39m\u001b[38;5;124m\"\u001b[39m, pipeline_response)\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (InvalidRequestParameter) The request is invalid. Details: definition : The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined.\nCode: InvalidRequestParameter\nMessage: The request is invalid. Details: definition : The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined.\nException Details:\t(UnknownVectorAlgorithmConfiguration) The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined. Parameters: definition\n\tCode: UnknownVectorAlgorithmConfiguration\n\tMessage: The field 'contentVector' uses a vector search algorithm configuration 'my-vector-config' which is not defined. Parameters: definition"
     ]
    }
   ],
   "source": [
    "# Replace with your actual connection string\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=storageaccountgenai;AccountKey=WAfyL4uqWgarFdx1ibNgWv9lmOINODLuN6nnLSQLgE/iuHhKGi1pYd6NQJ6LBnZO/DnnQfhbNSWi+AStsOLf1Q==;EndpointSuffix=core.windows.net\"\n",
    "\n",
    "# Replace with your container name\n",
    "container_name = \"safety\"\n",
    "\n",
    "# Create a BlobServiceClient using the connection string\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Get a reference to the container\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# List blobs in the container\n",
    "blobs = container_client.list_blobs()\n",
    "dict_data = []\n",
    "for blob in blobs:\n",
    "    #print(blob)\n",
    "    if blob.name.startswith(\"manuals\") and blob.name.endswith(\".pdf\"):  # Check if the blob is a PDF file\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        print(blob.name)\n",
    "        try:\n",
    "            pdf_files = blob_client.download_blob().readall()\n",
    "                # Save the blob content to a local PDF file or process it as needed\n",
    "            pdf_name = blob.name.split('/')[1]\n",
    "            print(pdf_name)\n",
    "            with open(pdf_name, \"wb\") as pdf_file:\n",
    "                pdf_file.write(pdf_files)\n",
    "                print(\"PDF file downloaded successfully.\")\n",
    "        except Exception as e:\n",
    "             print(f\"An error occurred: {e}\")       \n",
    "            \n",
    "        \n",
    "        #pdf_file_name=str(blob.name).split(\".\")[0]\n",
    "        #pdf_name = \"AAG_Safety_Manual.pdf\"\n",
    "        pdf_name = pdf_file_name\n",
    "\n",
    "        #loader = PyPDFLoader(pdf_name)\n",
    "        loader = pdf_text_extraction(pdf_name)\n",
    "        \n",
    "        documents = loader #.load()\n",
    "        #print(documents)\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        print(f\"splitted into {len(docs)} documents\") \n",
    "        \n",
    "        #vector_store.add_documents(documents=docs)\n",
    "        #print(docs)\n",
    "        \n",
    "\n",
    "        credential = AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY)\n",
    "        search_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, credential=credential)\n",
    "        search_client_v2 = SearchClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, index_name=AZURE_SEARCH_INDEX_NAME, credential=credential)\n",
    "\n",
    "        bid=str(blob.name).split(\"/\")[1].split(\".\")[0].lower().replace(\" \",\"_\").replace(\"_\",\"-\")\n",
    "        AZURE_SEARCH_INDEX_NAME=bid + \"-index\"\n",
    "        print(AZURE_SEARCH_INDEX_NAME)\n",
    "        # Define your Azure Cognitive Search credentials and index settings as previously done\n",
    "        # Check if the index already exists\n",
    "        existing_index = None\n",
    "        # Define your Azure Cognitive Search credentials and index settings as previously done\n",
    "        \n",
    "        \n",
    "        for doc in docs:\n",
    "            dict_data.append({\n",
    "                'id': blob.name,\n",
    "                'page_content': doc.page_content,  # You can set a title based on your needs\n",
    "                'page_number': doc.metadata['page'],\n",
    "            })\n",
    "\n",
    "        print(f\"splitted into {len(docs)} documents\") \n",
    "        \n",
    "        # Generate embeddings for title and content fields\n",
    "        for item in dict_data:\n",
    "            title = item['id']\n",
    "            content = item['page_content']\n",
    "            title_embeddings = embeddings.embed_query(title)\n",
    "            content_embeddings = embeddings.embed_query(content)\n",
    "            item['titleVector'] = title_embeddings\n",
    "            item['contentVector'] = content_embeddings\n",
    "            \n",
    "        print('111',dict_data)\n",
    "\n",
    "        #final_doc=[]\n",
    "        #for index,doc in enumerate(docs):\n",
    "        #   final_doc.append({'id':bid,'content':doc.page_content,'metadata':doc.metadata['source'], 'contentVector':content_embeddings[index]})\n",
    "        #print(final_doc,'!!')\n",
    "        # Generate embeddings for title and content fields   \n",
    "            \n",
    "            \n",
    "            # The index doesn't exist, so create a new one\n",
    "        if existing_index == None:\n",
    "            #index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME,fields=[SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),SearchableField(name=\"content_vector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single), searchable=True, vector_search_dimensions=1536,vector_search_configuration=\"my-vector-config\",),SearchableField(name=\"metadata\", type=SearchFieldDataType.String, searchable=True),],)\n",
    "            #index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME,fields=[SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),SearchableField(name=\"metadata\", type=SearchFieldDataType.String, searchable=True),],)\n",
    "            fields = [ \n",
    "                SimpleField(name = \"id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True),\n",
    "                SearchableField(name = 'content', type=SearchFieldDataType.String),\n",
    "                SearchableField(name='metadata', type=SearchFieldDataType.String),\n",
    "                SearchField(name=\"contentVector\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                        searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "\n",
    "            ]\n",
    "            index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME, fields = fields,)\n",
    "\n",
    "            # Create the new index\n",
    "            search_client.create_or_update_index(index)\n",
    "            #print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' created successfully.\")\n",
    "            result = search_client_v2.upload_documents(documents=dict_data)\n",
    "            print(\"Vector store added successfully\")\n",
    "\n",
    "        else:\n",
    "            try:\n",
    "                # Check if the index exists\n",
    "                existing_index = search_client.get_index(AZURE_SEARCH_INDEX_NAME)\n",
    "                print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' already exists. You can use the existing index.\")\n",
    "                #vector_store.add_documents(documents=final_doc)\n",
    "                result = search_client_v2.upload_documents(documents=dict_data)\n",
    "                print(f\"Uploaded {len(content)} documents\")\n",
    "                print(\"Vector store added successfully\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                pass\n",
    "        #document = [{\"id\": bid, \"content\": docs}]\n",
    "        #document = [{\"id\": doc[\"id\"], \"content\": doc[\"content\"]}]\n",
    "        #document = [{\"id\": doc.get_id(), \"content\": doc.get_content()}]\n",
    "\n",
    "\n",
    "        # Submit the documents for indexing\n",
    "        #result = search_client.upload_documents(documents=final_do)\n",
    "        #vector_store.add_documents(documents=final_doc)\n",
    "        #print(\"Vector store added successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "39a40cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.name = \"manuals/Alaska Airlines and Horizon Air SMS Manual.pdf\" #delete this later and merge the below and above cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2cb4b55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#embeddings_result = embeddings.embed_query(text)\n",
    "\n",
    "for item in docs:\n",
    "    content = item.page_content\n",
    "    content_embeddings = embeddings.embed_query(content)\n",
    "    #item['contentVector'] = content_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59ab34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26add8ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Uncontrolled copy when downloaded or printed from an electronic document.\\nSafety Management System \\n(SMS) Manual\\nAlaska Airlines, Inc. / Horizon Air\\n(Alaska Air Group)\\nRevision 18 6/16/2023', metadata={'source': '/var/folders/g1/zd40wpl1023dlyqyjv2xplcc0000gq/T/tmpjth72l2u', 'page': 0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df73b137",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cab957",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65898370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pure Vector Search\n",
    "from azure.search.documents.models import Vector\n",
    "query = \"software development\"  \n",
    "  \n",
    "vector = Vector(value=generate_embeddings(query), k=3, fields=\"contentVector\")\n",
    "  \n",
    "results = search_client_v2.search(  \n",
    "    search_text=None,  \n",
    "    vectors= [vector],\n",
    "    select=[\"id\", \"content\", \"metadata\"],\n",
    ")  \n",
    "  \n",
    "for result in results:  \n",
    "    print(f\"Title: {result['title']}\")  \n",
    "    print(f\"Score: {result['@search.score']}\")  \n",
    "    print(f\"Content: {result['content']}\")  \n",
    "    print(f\"Category: {result['category']}\\n\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf7018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5d42c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "f = vector_store.similarity_search(\n",
    "    query=\"what is requirement for responsible ai?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(f[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc52cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bce692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Handle the case where the user doesn't provide ids on the Collection\n",
    "texts = [doc.page_content for doc in docs]\n",
    "#print(texts)\n",
    "metadatas = [doc.metadata for doc in docs]\n",
    "print(metadatas[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb94ee9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b79ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(docs)\n",
    "res=[]\n",
    "for doc in docs:\n",
    "    res.append({'id':bid,'content':doc.page_content,'metadata':doc.metadata})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c1643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421c284",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5ad5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade azure-search-documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623bc398",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeda0c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5080ee21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75031eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05439ee1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd084c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c557dcb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36647e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d75203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_stream):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        pdf_reader = PyPDF2.PdfFileReader(pdf_stream)\n",
    "        num_pages = pdf_reader.numPages\n",
    "        for page_num in range(num_pages):\n",
    "            page = pdf_reader.getPage(page_num)\n",
    "            text += page.extractText()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "pdf_text = extract_text_from_pdf(pdf_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446995d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = SearchIndex(\n",
    "    name=AZURE_SEARCH_INDEX_NAME,\n",
    "    fields=[\n",
    "        SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),\n",
    "        SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),\n",
    "    ],\n",
    ")\n",
    "index\n",
    "#search_client.create_index(index)\n",
    "\n",
    "\n",
    "try:\n",
    "    result = search_client.get_index(index_name)\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402a26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a0b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n",
    "\n",
    "def extract_text_from_pdf(pdf_file_path):\n",
    "    text = \"\"\n",
    "    try:\n",
    "        with open(pdf_file_path, 'rb') as pdf_file:\n",
    "            pdf_reader = PyPDF2.PdfFileReader(pdf_file)\n",
    "            num_pages = pdf_reader.numPages\n",
    "            for page_num in range(num_pages):\n",
    "                page = pdf_reader.getPage(page_num)\n",
    "                text += page.extractText()\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {str(e)}\")\n",
    "    return text\n",
    "\n",
    "\n",
    "# Initialize the SearchIndexClient and SearchClient\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY)\n",
    "search_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, credential=credential)\n",
    "search_client_v2 = SearchClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, index_name=AZURE_SEARCH_INDEX_NAME, credential=credential)\n",
    "# Replace with your actual connection string\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=storageaccountgenai;AccountKey=WAfyL4uqWgarFdx1ibNgWv9lmOINODLuN6nnLSQLgE/iuHhKGi1pYd6NQJ6LBnZO/DnnQfhbNSWi+AStsOLf1Q==;EndpointSuffix=core.windows.net\"\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "# Replace with your container name\n",
    "container_name = \"safety\"\n",
    "# Get a reference to the container\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# List blobs in the container\n",
    "blobs = container_client.list_blobs()\n",
    "for blob in blobs:\n",
    "    #print(blob)\n",
    "    if blob.name.startswith(\"manuals\") and blob.name.endswith(\".pdf\"):  # Check if the blob is a PDF file\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        pdf_files = blob_client.download_blob().readall()\n",
    "        print(type(pdf_files))\n",
    "        pdf_file_name=str(blob.name).split(\".\")[0]\n",
    "        loader = AzureBlobStorageContainerLoader(conn_str=connection_string,container=container_name,prefix=pdf_file_name,)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        print(docs)\n",
    "        # Define the index with 'id' and 'content' fields\n",
    "        bid=str(blob.name).split(\"/\")[1].split(\".\")[0].lower().replace(\" \",\"_\").replace(\"_\",\"-\")\n",
    "        AZURE_SEARCH_INDEX_NAME=bid + \"-index\"\n",
    "        index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME,fields=[SimpleField(name=\"id\", type=\"Edm.String\", key=True, searchable=False),SearchableField(name=\"content\", type=\"Edm.String\", searchable=True),],)\n",
    "        # Create the index if it doesn't exist\n",
    "        existing_index = None\n",
    "        # Define your Azure Cognitive Search credentials and index settings as previously done\n",
    "        try:\n",
    "            # Check if the index exists\n",
    "            existing_index = search_client.get_index(AZURE_SEARCH_INDEX_NAME)\n",
    "            print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' already exists. You can use the existing index.\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # The index doesn't exist, so create a new one\n",
    "        if existing_index == None:\n",
    "            index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME,fields=[SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),],)\n",
    "            # Create the new index\n",
    "            search_client.create_index(index)\n",
    "            print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' created successfully.\")\n",
    "        #document = [{\"id\": bid, \"content\": docs}]\n",
    "        #document = [{\"id\": doc[\"id\"], \"content\": doc[\"content\"]}]\n",
    "        #document = [{\"id\": doc.get_id(), \"content\": doc.get_content()}]\n",
    "        documents = [{\"id\": bid, \"content\": pdf_text}]\n",
    "        search_client_v2.upload_documents(documents=documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29725e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "blobs = container_client.list_blobs()\n",
    "for blob in blobs:\n",
    "    if blob.name.startswith(\"manuals\") and blob.name.endswith(\".pdf\"):  # Check if the blob is a PDF file\n",
    "        print('yes')\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        pdf_files = blob_client.download_blob().readall()\n",
    "        pdf_file_name=str(blob.name).split(\"/\")[1]\n",
    "        print(pdf_file_name)\n",
    "        pdf_text = extract_text_from_pdf(pdf_file_name)\n",
    "        print(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675eb8c2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##########################CODE BASE#########################\n",
    "credential = AzureKeyCredential(AZURE_SEARCH_ADMIN_KEY)\n",
    "search_client = SearchIndexClient(endpoint=AZURE_SEARCH_SERVICE_ENDPOINT, credential=credential)\n",
    "\n",
    "#embeddings: OpenAIEmbeddings = OpenAIEmbeddings(deployment=\"textembeddingada\", model = \"text-embedding-ada-002\", chunk_size=1)\n",
    "embeddings = OpenAIEmbeddings(deployment = model,chunk_size=1) \n",
    "#vector_store: AzureSearch = AzureSearch(\n",
    "#    azure_search_endpoint=AZURE_SEARCH_SERVICE_ENDPOINT,\n",
    "#    azure_search_key=AZURE_SEARCH_ADMIN_KEY,\n",
    "#    index_name = AZURE_SEARCH_INDEX_NAME,\n",
    "#    embedding_function=embeddings.embed_query,\n",
    "#)\n",
    "\n",
    "def pdf_text_extraction(pdf_file_path):\n",
    "    if pdf_file_path is not None:\n",
    "        # Open the PDF file and read its contents\n",
    "        with open(pdf_file_path, 'rb') as pdf_file:\n",
    "            # Create a temporary file to write the PDF contents\n",
    "            with tempfile.NamedTemporaryFile(delete=False) as tmp_file:\n",
    "                tmp_file.write(pdf_file.read())\n",
    "                pdf_path = tmp_file.name\n",
    "\n",
    "        # Now you can use the PyPDFLoader on the temporary PDF file\n",
    "        loader = PyPDFLoader(pdf_path)\n",
    "        pages_split = loader.load_and_split()\n",
    "    return pages_split\n",
    "\n",
    "import tempfile\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "#pdf_file_name = \"Alaska Airlines and Horizon Air SMS Manual.pdf\"\n",
    "\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "# Replace with your actual connection string\n",
    "connection_string = \"DefaultEndpointsProtocol=https;AccountName=storageaccountgenai;AccountKey=WAfyL4uqWgarFdx1ibNgWv9lmOINODLuN6nnLSQLgE/iuHhKGi1pYd6NQJ6LBnZO/DnnQfhbNSWi+AStsOLf1Q==;EndpointSuffix=core.windows.net\"\n",
    "# Create a BlobServiceClient\n",
    "blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "\n",
    "# Replace with your container name\n",
    "container_name = \"safety\"\n",
    "\n",
    "# Get a reference to the container\n",
    "container_client = blob_service_client.get_container_client(container_name)\n",
    "\n",
    "# List blobs in the container\n",
    "blobs = container_client.list_blobs()\n",
    "\n",
    "for blob in blobs:\n",
    "    #print(blob)\n",
    "    if blob.name.startswith(\"manuals\") and blob.name.endswith(\".pdf\"):  # Check if the blob is a PDF file\n",
    "        blob_client = container_client.get_blob_client(blob)\n",
    "        pdf_files = blob_client.download_blob().readall()  \n",
    "        #pages = pdf_text_extraction(pdf_file_name)\n",
    "        #print(blob)\n",
    "        loader = PyPDFLoader(pdf_file_name)\n",
    "        documents = loader.load()\n",
    "        text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "        docs = text_splitter.split_documents(documents)\n",
    "        bid=str(blob.name).split(\"/\")[1].split(\".\")[0].lower().replace(\" \",\"_\").replace(\"_\",\"-\")\n",
    "        AZURE_SEARCH_INDEX_NAME=bid + \"-index\"\n",
    "        print(AZURE_SEARCH_INDEX_NAME)\n",
    "        # Define your Azure Cognitive Search credentials and index settings as previously done\n",
    "        # Check if the index already exists\n",
    "        existing_index = None\n",
    "        # Define your Azure Cognitive Search credentials and index settings as previously done\n",
    "        try:\n",
    "            # Check if the index exists\n",
    "            existing_index = search_client.get_index(AZURE_SEARCH_INDEX_NAME)\n",
    "            print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' already exists. You can use the existing index.\")\n",
    "        except Exception as e:\n",
    "            pass\n",
    "            # The index doesn't exist, so create a new one\n",
    "        if existing_index == None:\n",
    "            index = SearchIndex(name=AZURE_SEARCH_INDEX_NAME,fields=[SimpleField(name=\"id\", type=SearchFieldDataType.String, key=True, searchable=False),SearchableField(name=\"content\", type=SearchFieldDataType.String, searchable=True),],)\n",
    "            # Create the new index\n",
    "            search_client.create_index(index)\n",
    "            print(f\"Index '{AZURE_SEARCH_INDEX_NAME}' created successfully.\")\n",
    "        #document = [{\"id\": bid, \"content\": docs}]\n",
    "        #document = [{\"id\": doc[\"id\"], \"content\": doc[\"content\"]}]\n",
    "        document = [{\"id\": doc.get_id(), \"content\": doc.get_content()}]\n",
    "        #print(documents)\n",
    "        # Add the documents to the Azure Cognitive Search index\n",
    "        vector_store: AzureSearch = AzureSearch(azure_search_endpoint=AZURE_SEARCH_SERVICE_ENDPOINT,azure_search_key=AZURE_SEARCH_ADMIN_KEY,index_name = AZURE_SEARCH_INDEX_NAME,embedding_function=embeddings.embed_query,)\n",
    "        vector_store.add_documents(documents=document)\n",
    "        #print(\"vector Created Successfully.\")\n",
    "\n",
    "            # Continue with the rest of your code, such as extracting text from PDFs and adding to the index\n",
    "        #search_client.create_index(index)\n",
    "        #docs\n",
    "        #vector_store.add_documents(documents=docs)\n",
    "        \n",
    "\n",
    "#blobs = container_client.list_blobs()\n",
    "#for blob in blobs:\n",
    "#    print(blob.name)\n",
    "\n",
    "#loader = PyPDFLoader(\"Alaska Airlines and Horizon Air SMS Manual.pdf\")\n",
    "#pages = loader.load_and_split()\n",
    "\n",
    "#documents = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba370eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=docs)\n",
    "\n",
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"safety Actions\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "print(docs[0].page_content)\n",
    "docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c4ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "--end--\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962bc0d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8b7a82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
